services:
 
  dpad_llc_home:
    build: ./frontend
    container_name: dpad_llc_home 
    hostname: dpad_llc_home 
    restart: always
    ports: 
      - 80:80 
      - 443:443 
    networks:
      - dpad_llc
  
  dpad_llc_api:
    build: ./backend
    container_name: dpad_llc_api 
    hostname: dpad_llc_api 
    restart: always
    ports:
      - 8082:8082
    environment:
      - WEBPAGE_API_PORT=8082
      - DB_USER_NAME=root
      - DB_PASSWORD=dpad_db
      - DB_HOST_NAME=dpad_llc_db
    networks:
      - dpad_llc  
    volumes:
      - ./backend/app:/app
  
  dpad_llc_db:
    image: mariadb:latest
    container_name: dpad_llc_db 
    restart: always
    hostname: dpad_llc_db
    volumes:
      - type: bind 
        source: ./database/.db
        target: /var/lib/mysql
      - type: bind 
        source: ./database/perms.sql
        target: /docker-entrypoint-initdb.d/perms.sql
    environment:
      - MARIADB_ROOT_PASSWORD=dpad_db
    networks:
      - dpad_llc

  llama:
    image: ghcr.io/ggml-org/llama.cpp:server 
    container_name: llama-server
    restart: unless-stopped
    ports:
      - "7000:7000"
    networks:
      - dpad_llc 
    volumes:
      - ./ai_server/models:/models:ro
    command: >
      -m /models/meta-llama-3-8b-instruct.Q4_K_M.gguf
      --ctx-size 4096
      --threads 12
      --batch-size 256
      --host 0.0.0.0
      --port 7000 
    deploy:
      resources:
        limits:
          cpus: "16"
    profiles:
      - ai

networks:
  dpad_llc:
    driver: bridge
    name: dpad_llc
    external: true

